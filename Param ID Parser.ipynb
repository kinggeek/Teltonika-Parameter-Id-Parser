{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4275704",
   "metadata": {},
   "source": [
    "# Teltonika Data Sending Parameter ID Parser\n",
    "\n",
    "## Panagiotis Kalogeropoulos, OpenRemote\n",
    "## panos.kalogeropoulos@openremote.io\n",
    "\n",
    "This Jupyter Notebook helps parse the Teltonika-GPS Wiki page for the data sending parameter IDs into a Pandas dataframe, which can then be exported into various types, like Excel or JSON. \n",
    "\n",
    "By parsing the table into programmatically accessible data, we are able to programmatically determine what parameter each Teltonika device is talking about. In this way, we can easily generalize to the entire line of Teltonika GPS Trackers.\n",
    "\n",
    "In OpenRemote, this script will be used to automatically map parameters sent over by any Teltonika device into the correct attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c6a8ed",
   "metadata": {},
   "source": [
    "\n",
    "# Import required packages\n",
    "\n",
    "Some packages are not being used directly, but they are required by other packages to run the application with no issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pyarrow\n",
    "import lxml\n",
    "from re import sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b449b80",
   "metadata": {},
   "source": [
    "# Set Variables\n",
    "\n",
    "The `device` variable is where the user would enter their device number, to retrieve the correct data from the Teltonika website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ca9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = input(\"Enter Teltonika Telematics Model Number\")\n",
    "url=\"https://wiki.teltonika-gps.com/view/\"+device+\"_Teltonika_Data_Sending_Parameters_ID\"\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfebc7f",
   "metadata": {},
   "source": [
    "# Download HTML of URL and parse into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dfList = pandas.read_html(url, header=1, encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3fd062bfae01924",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "⚠️Warning!⚠️\n",
    "\n",
    "If you get an error relating to HTTP requests, you can change the `url` variable to point to the HTML file you manually downloaded from the website. This may happen to potential flagging of your IP address, as the Teltonika website uses Cloudflare to protect against abusive HTTP requests."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c2d687151d9777e"
  },
  {
   "cell_type": "markdown",
   "id": "fe780ccd",
   "metadata": {},
   "source": [
    "# Adjust DataFrames to export\n",
    "\n",
    "Specifically, the page contains multiple tables, for example \"Permanent I/O Elements\", \"Eventual I/O elements\", etc.\n",
    "\n",
    "Thus, by combining the tables, we gather a singular table with the Parameter Group column guaranteeing no data loss from the concatenation."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DataFrame adjustments\n",
    "\n",
    "Converting headers to camelCase"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3484e390a216fa7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def camel_case(s):\n",
    "    s = sub(r\"(_|-)+\", \" \", s).title().replace(\" \", \"\")\n",
    "    return ''.join([s[0].lower(), s[1:]])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38122d34ac1d073e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_copy = dfList.copy()\n",
    "\n",
    "for df in df_copy:\n",
    "    df.rename(columns=camel_case, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfa05fb8f96d736",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# These properties are the only ones we ACTUALLY require. \n",
    "# The rest can be a \"-\", and we can handle that. \n",
    "# As long as we have those, we're set. \n",
    "# Worst case scenario, the values are parsed as strings,\n",
    "# And someone goes through those SPECIFIC properties,\n",
    "# Adds the types, and proceeds. People can do a find and replace.\n",
    "required_columns = {\"propertyIdInAvlPacket\", \"propertyName\", \"type\"}\n",
    "main_columns = set(df_copy[0].columns)\n",
    "\n",
    "\n",
    "for idx, df in enumerate(df_copy):\n",
    "    if required_columns.issubset(df.columns):\n",
    "        # Drop all elements that are in df.columns but not main_columns\n",
    "        df.drop(list(df.columns.difference(main_columns)), axis=1, inplace=True)\n",
    "        #find the columns that exist in main_columns and not in df.columns\n",
    "        missing = main_columns.difference(df.columns)\n",
    "        # Fill in the value as \"-\", as Teltonika does\n",
    "        for col in missing:\n",
    "            df[col] = \"-\"\n",
    "    # if the selected `df` does not contain the basic required_columns, just drop it from the list.\n",
    "    # We cannot cover every single edge case. The best thing we can do is let the user know.\n",
    "    else: \n",
    "        print(\"DATAFRAME CORRUPTED - CANNOT PARSE:\")\n",
    "        print(df)\n",
    "        df_copy.pop(idx)\n",
    "\n",
    "megaDf = pandas.concat(df_copy, ignore_index=True)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d93d979e4c1efe78",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d0d89b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop the index that was automatically inserted\n",
    "megaDf.reset_index(drop=True, inplace=True)\n",
    "megaDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53329499",
   "metadata": {},
   "source": [
    "# Export to files\n",
    "\n",
    "Look into the pandas documentation for other export types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "megaDf.to_excel(device+\".xlsx\")\n",
    "# Dealing with Unicode errors\n",
    "with open(device+\".json\", 'w', encoding='utf-8') as file:\n",
    "    megaDf.to_json(file, force_ascii=False, orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Show data types\n",
    "\n",
    "Using the below command, we can see the unique data types in the exported file, that will be used by OpenRemote to determine the type of the received value."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd6fe058b159b315"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2497d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(megaDf['type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check the file!\n",
    "\n",
    "Go ahead and check the file. Use various tools to plot the file into a table, or export it as an excel file, to see the exported results. Fix any issues, and then import it into OpenRemote. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afd767632df92142"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
